{% set name = "datasets" %}
{% set version = "2.21.0" %}


package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/{{ name }}-{{ version }}.tar.gz
  sha256: 998f85a8460f1bd982e5bd058f8a0808eef424249e3df1e8cdd594ccd0dc8ba2

build:
  noarch: python
  number: 0
  entry_points:
    - datasets-cli=datasets.commands.datasets_cli:main
  script: {{ PYTHON }} -m pip install . -vv

requirements:
  host:
    - pip
    - python >=3.8.0
  run:
    - python >=3.8.0
    - filelock
    - numpy >=1.17
    - pyarrow >=15.0.0
    - pyarrow-hotfix
    - dill >=0.3.0,<0.3.9
    - pandas
    - requests >=2.32.2
    - tqdm >=4.66.3
    - python-xxhash
    - multiprocess
    - fsspec >=2023.1.0,<=2024.5.0
    - huggingface_hub >=0.21.2
    - packaging
    - pyyaml >=5.1
    # For fsspec[http]
    - aiohttp !=4.0.0a0,!=4.0.0a1

test:
  imports:
    - datasets
  commands:
    - pip check
    - datasets-cli --help
  requires:
    - pip

about:
  home: https://github.com/huggingface/datasets
  license: Apache-2.0
  license_family: Apache
  license_file: LICENSE
  summary: HuggingFace/Datasets is an open library of NLP datasets.
  description: |
    Datasets is a lightweight library providing one-line dataloaders for many
    public datasets and one liners to download and pre-process any of the number
    of datasets major public datasets provided on the HuggingFace Datasets Hub.
    Datasets are ready to use in a dataloader for training/evaluating a ML model
    (Numpy/Pandas/PyTorch/TensorFlow/JAX). Datasets also provide an API for
    simple, fast, and reproducible data pre-processing for the above public
    datasets as well as your own local datasets in CSV/JSON/text.
  doc_url: https://huggingface.co/docs/datasets/
  dev_url: https://github.com/huggingface/datasets

extra:
  recipe-maintainers:
    - oblute
    - Tata17
    - thewchan
    - mxr-conda
